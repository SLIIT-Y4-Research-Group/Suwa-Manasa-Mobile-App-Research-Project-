{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SLIIT-Y4-Research-Group/Suwa-Manasa-Mobile-App-Research-Project-/blob/Kavindi/GRU_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tuning GRU Model for Katha Mithura"
      ],
      "metadata": {
        "id": "TOuj43Taybtl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup Google Colab & Mount Drive"
      ],
      "metadata": {
        "id": "jkNIVGOPyxt9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mount Google Drive"
      ],
      "metadata": {
        "id": "RrJ8btSLy6Qv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSZyX9ZiyLjH",
        "outputId": "6097c460-208d-4143-efa7-6e828744e053"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Navigate to dataset folder"
      ],
      "metadata": {
        "id": "5GA4uM2by-LN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "dataset_path = \"/content/drive/My Drive/ResearchStory/dataset2\"\n",
        "os.listdir(dataset_path)"
      ],
      "metadata": {
        "id": "-9qxOqbIzBCM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6943d1fa-e874-46a8-fbd9-010784989f11"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['හා හාමිගේ කතාව.txt',\n",
              " 'අම්මා.txt',\n",
              " 'ගමරාළ පිට්ටු උයපු හැටි.txt',\n",
              " 'වලිගෙ තමයි ලෙඩේ.txt',\n",
              " 'රයිගමයයි ගම්පලයයි.txt',\n",
              " 'සිල් ගත්ත පූසා.txt',\n",
              " 'රාජා හෝ, මා හෝ, ගංගා හෝ.txt',\n",
              " 'හීනැටි හාලෙ බත් කෑ ගමරාල – 2.txt',\n",
              " 'ගමරාල හීනැටි හාලෙ බත් කෑ හැටි.txt',\n",
              " 'බත් අමු වූ හැටි.txt',\n",
              " 'නටපු නැටුමකුත් නෑ බෙරේ පලුවකුත් නෑ.txt',\n",
              " 'ගමරාලගෙ දූ පොඩිත්ත – 2.txt',\n",
              " 'ගමරාලගෙ දූ පොඩිත්ත.txt',\n",
              " 'සුළඟේ ගිය පුළුන් ගුලිය – ඉතිරිය.txt',\n",
              " 'සුළඟේ ගිය පුළුන් ගුලිය.txt',\n",
              " 'රාජකීය විකට නළු අන්දරේ.txt',\n",
              " 'මහා සෝන යක්ෂයා හෙවත් රිටිගල ජයසේන.txt',\n",
              " 'ගොවියා ස්වර්ගයට ගියේය.txt',\n",
              " 'කලාගේ කතාව.txt',\n",
              " 'කටුවල කෑම.txt',\n",
              " 'ගමරාලයි නරි නයිදෙයි.txt',\n",
              " 'රජ්ජුරුවෝ කුඩු කෑවා.txt',\n",
              " 'අන්දරේ - ශ්\\u200dරී ලංකාවේ ප්\\u200dරසිද්ධ උසාවි විහිළුකාරයා.txt',\n",
              " 'රාජකීය පොකුණේ අන්දරේ.txt',\n",
              " 'අන්දරේගේ බිරිඳ සහ රැජින.txt',\n",
              " 'අන්දරේ රජුගේ ජම්බු කෑ ආකාරය.txt',\n",
              " 'මවුන්ට් ලවීනියාව.txt',\n",
              " 'සිංහබාහු.txt',\n",
              " 'රාම සහ සීතා.txt',\n",
              " 'විහාර මහා දේවි රැජින.txt',\n",
              " 'සීගිරියේ පුරාවෘත්තය.txt',\n",
              " 'ගමරාලගේ දියණිය.txt',\n",
              " 'මහා පෘථිවිය නිර්මාණය කිරීම.txt',\n",
              " 'ඉර, හඳ සහ මහා වී.txt',\n",
              " 'සෙනසුරාගේ කතාව.txt',\n",
              " 'වීදුරු කුමරිය.txt',\n",
              " 'ගෙම්බා කුමාරයා.txt',\n",
              " 'මෙනේරි වෙළෙන්දා.txt',\n",
              " 'කැස්බෑ පරෙවියා.txt',\n",
              " 'කුමාරයා සහ කුමාරිය.txt',\n",
              " 'දෙමල් ටික්කා.txt',\n",
              " 'මාතලංගෙ ලොකු-අප්පු.txt',\n",
              " 'සුදු කැස්බෑවා.txt',\n",
              " 'කළු මැණියාගේ දියණිය.txt',\n",
              " 'රන් කෑකිරි ගෙඩිය.txt',\n",
              " 'බිහිරි මිනිස්සු හතරදෙනා.txt',\n",
              " 'කුමාරයා සහ යකා.txt',\n",
              " 'යකා සහ මිනිසා සටන් කළ ආකාරය.txt',\n",
              " 'මිනිසෙක් සහ යකාවරුන් දෙදෙනෙකු.txt',\n",
              " 'ප්\\u200dරශ්න තුන.txt',\n",
              " 'විශ්වාසවන්ත නොවන රැජින.txt',\n",
              " 'පාසලට නොගිය කුමාරයා.txt',\n",
              " 'නගුල්–මුන්නා.txt',\n",
              " 'කුලේ-බකා මල්.txt',\n",
              " 'කුරුලු-ගම අප්පු – ජෝතිෂ්කාරයා.txt',\n",
              " 'යක්ෂණියක් විසින් කුමාරයෙකු පසුපස හඹා ගිය හැටි සහ සිදු වූ දේ.txt',\n",
              " 'කතා කරන අශ්වයා.txt',\n",
              " 'දුෂ්ට රජු.txt',\n",
              " 'ගැහැනු කුකුළා.txt',\n",
              " 'බොවුල්ලා සහ හරකා.txt',\n",
              " 'පාටැති රොබින්.txt',\n",
              " 'සිංහයා සහ මීමිනි.txt',\n",
              " 'මැඩිගැටළුවේ මෝඩ කබරයා.txt',\n",
              " 'ගමරාලගේ කේක්.txt',\n",
              " 'කින්නරා සහ තිලංඟන්.txt',\n",
              " 'හිවලුන් සහ කුඹුරු කඩල.txt',\n",
              " 'හිවලුන් විසින් නඩුවක් විසඳීම.txt',\n",
              " 'සිංහයා සහ කුඹුරු කඩල.txt',\n",
              " 'වඳුරා සහ නූල්කුරු කුරුල්ලෝ.txt',\n",
              " 'හිවලුන් දෙවතාවා.txt',\n",
              " 'කඩම්බාව පුද්ගලයෙකුගේ පුත්තලමට ගමන.txt',\n",
              " 'කඩම්බාව ජනතාව තමන් ගණන් කළ ආකාරය.txt',\n",
              " 'කඩම්බාව පුද්ගලයෝ සහ සිහින.txt',\n",
              " 'හතර ටොම්-ටොම් වාදකයෝ.txt',\n",
              " 'රන් ගස.txt',\n",
              " 'හත දියණියන්.txt',\n",
              " 'මහතා ජැනෙල් සින්ඤා.txt',\n",
              " 'නිකිනි කතාව.txt',\n",
              " 'ඇට්-කන්ද ලේනි.txt',\n",
              " 'විමලි කතාව.txt',\n",
              " 'තෙල් පොතු.txt',\n",
              " 'මූස් කුමාරි කතාව.txt',\n",
              " 'සීගිරිස් සින්ඤෝ, මහතා.txt',\n",
              " 'හත් දෙනෙකුගේ හොරාන් කතාව.txt',\n",
              " 'මෝඩ කොළයෙක්.txt',\n",
              " 'ගමරාල සහ රෙදිවෙළයාගේ කතාව.txt',\n",
              " 'දෙදෙනෙක්ම කපට්ටුකාරයෝ.txt',\n",
              " 'මාර්ගෝස ගස.txt',\n",
              " 'ගමරාළගේ මෝඩ පුත්.txt',\n",
              " 'හිවලාගේ විනිශ්චය.txt',\n",
              " 'ධර්ම රක්ෂිතය වූ පූසා.txt',\n",
              " 'සර්පයා සහ චිත්තියා.txt',\n",
              " 'හිවලා සහ බ්\\u200dරාහ්මණයා.txt',\n",
              " 'පුංචි රෝලය.xtx.ini',\n",
              " 'සිංහයා සහ හිවලා.txt',\n",
              " 'හන්දියන් රාක්ෂසයා කොහොම මරා දැමූහද.txt',\n",
              " 'කෘතඥ හිවලා.txt',\n",
              " 'සංඝියා හා යකඩයා ගැන.txt',\n",
              " 'තිදෙනාගේ මංගල ඉල්ලුම්කරුවන්.txt',\n",
              " 'මැඩුම සහ වඹලා.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load & Explore Dataset"
      ],
      "metadata": {
        "id": "VrQRpQhO7T_d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import re\n",
        "\n",
        "# Load dataset (adjust based on file type)\n",
        "def load_stories_from_folder(folder_path):\n",
        "    stories = []\n",
        "    for file_name in os.listdir(folder_path):\n",
        "        if file_name.endswith('.txt'):\n",
        "            with open(os.path.join(folder_path, file_name), 'r', encoding='utf-8') as f:\n",
        "                stories.append(f.read())\n",
        "    return stories\n",
        "\n",
        "stories = load_stories_from_folder(dataset_path)\n",
        "print(f\"Total stories: {len(stories)}\")\n",
        "print(\"First story preview:\", stories[0][:500])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4GvQeaM7VYk",
        "outputId": "e43a756e-3b23-4da6-8df7-9c113ad1bce2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total stories: 99\n",
            "First story preview: ඔන්න එක කැලයක ලස්සන හාවෙක් ජිවත් වුණා. මේ හාවාට තිබුණා ලස්සන දිග රැවුලක්. දවසක් මේ හාවාට හිතුණා උගේ රැවුල කපන්න. ඉතින් හාවා බාබර් සාප්පුවට ගියා රැවුල කපාගන්න.\n",
            "\n",
            "''කරුණාකරලා මගේ මේ රැවුල කපනවද?'' හාවා බාබර් උන්නැහේට කිව්වා.\n",
            "\n",
            "බාබර් උන්නැහේත් හාවාගේ රැවුල කැපුවා.\n",
            "\n",
            "හාවා හරි සතුටින් ගෙදර ගියා. ටික වෙලාවක් යනකොට හාවාට හිතුණා ''අනේ මගේ රැවුල තිබුණන් කොච්චර හොදද'' කියලා. හාවා ආපහු බාබර් සාප්පුවට ගිහින් එයාගෙ රැවුල ඉල්ලුවා.\n",
            "\n",
            "''මම කොහොමද ඔයාගේ රැවුල දෙන්නෙ. මෙච්චර වෙලා කපපු රැවුල්, කොණ්ඩ ඔක්කොම අතුගාලා දැ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clean & Preprocess Text"
      ],
      "metadata": {
        "id": "zCB6fbjy7cPk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_sinhala_text(text):\n",
        "    # Remove non-Sinhala characters and extra whitespace\n",
        "    text = re.sub(r'[^අ-ෆ.,!?…\\s]', '', text)\n",
        "    # Normalize whitespace\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "cleaned_stories = [clean_sinhala_text(story) for story in stories]\n",
        "print(\"Cleaned sample:\", cleaned_stories[0][:300])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohTs8wGa7dBE",
        "outputId": "c8405d8d-cc2b-4cf3-9900-4e68a95233a8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned sample: ඔනන එක කලයක ලසසන හවක ජවත වණ. ම හවට තබණ ලසසන දග රවලක. දවසක ම හවට හතණ උග රවල කපනන. ඉතන හව බබර සපපවට ගය රවල කපගනන. කරණකරල මග ම රවල කපනවද? හව බබර උනනහට කවව. බබර උනනහත හවග රවල කපව. හව හර සතටන ගදර ගය. ටක වලවක යනකට හවට හතණ අන මග රවල තබණන කචචර හදද කයල. හව ආපහ බබර සපපවට ගහන එයග රවල ඉලලව. මම කහමද ඔයග රවල දනන.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build Character Vocabulary"
      ],
      "metadata": {
        "id": "OE_rfTOh7lls"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine all stories\n",
        "full_text = ' '.join(cleaned_stories)\n",
        "chars = sorted(list(set(full_text)))\n",
        "print(f\"Total unique characters: {len(chars)}\")\n",
        "\n",
        "# Create character mappings\n",
        "char_to_idx = {ch: i for i, ch in enumerate(chars)}\n",
        "idx_to_char = {i: ch for i, ch in enumerate(chars)}\n",
        "\n",
        "# Save vocabulary\n",
        "vocab_path = \"/content/drive/My Drive/ResearchStory/vocabulary/\"\n",
        "os.makedirs(vocab_path, exist_ok=True)\n",
        "\n",
        "with open(os.path.join(vocab_path, 'char_to_idx.json'), 'w', encoding='utf-8') as f:\n",
        "    json.dump(char_to_idx, f, ensure_ascii=False)\n",
        "\n",
        "with open(os.path.join(vocab_path, 'idx_to_char.json'), 'w', encoding='utf-8') as f:\n",
        "    json.dump(idx_to_char, f, ensure_ascii=False)\n",
        "\n",
        "print(\"Vocabulary saved.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjqNViIf7mck",
        "outputId": "4b41e611-7126-43f5-a2f1-5fb92e5bfe5f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total unique characters: 55\n",
            "Vocabulary saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare Training Sequences"
      ],
      "metadata": {
        "id": "hBLd6puv82ZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Convert text to indices\n",
        "text_as_int = [char_to_idx[ch] for ch in full_text]\n",
        "\n",
        "# Parameters\n",
        "SEQ_LENGTH = 100  # Context window\n",
        "STEP_SIZE = 3     # Stride for creating more sequences\n",
        "\n",
        "# Create sequences\n",
        "sequences = []\n",
        "next_chars = []\n",
        "\n",
        "for i in range(0, len(text_as_int) - SEQ_LENGTH, STEP_SIZE):\n",
        "    sequences.append(text_as_int[i:i + SEQ_LENGTH])\n",
        "    next_chars.append(text_as_int[i + SEQ_LENGTH])\n",
        "\n",
        "# Convert to numpy arrays\n",
        "X = np.array(sequences)\n",
        "y = np.array(next_chars)\n",
        "\n",
        "print(f\"Total sequences: {len(X)}\")\n",
        "print(f\"X shape: {X.shape}, y shape: {y.shape}\")\n",
        "\n",
        "# One-hot encode y for categorical crossentropy\n",
        "y_categorical = to_categorical(y, num_classes=len(chars))\n",
        "print(f\"y_categorical shape: {y_categorical.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrAZUAhp86N8",
        "outputId": "a9cc6cc4-3fd0-4a2b-e009-5c33b96a11e2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total sequences: 58812\n",
            "X shape: (58812, 100), y shape: (58812,)\n",
            "y_categorical shape: (58812, 55)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build Enhanced GRU Model"
      ],
      "metadata": {
        "id": "Mf2Lv5IK8-L8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, GRU, Dense, Dropout, BatchNormalization, Bidirectional\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Parameters\n",
        "VOCAB_SIZE = len(chars)\n",
        "EMBEDDING_DIM = 256\n",
        "GRU_UNITS = 512\n",
        "\n",
        "# Build model WITH implementation=2 for TFLite compatibility\n",
        "model = Sequential([\n",
        "    Embedding(VOCAB_SIZE, EMBEDDING_DIM),\n",
        "    Bidirectional(\n",
        "    GRU(\n",
        "        GRU_UNITS,\n",
        "        return_sequences=True,\n",
        "        implementation=2,\n",
        "        reset_after=True,\n",
        "        recurrent_activation='sigmoid'\n",
        "    )\n",
        "),\n",
        "    Dropout(0.3),\n",
        "    BatchNormalization(),\n",
        "    Bidirectional(\n",
        "    GRU(\n",
        "        GRU_UNITS,\n",
        "        implementation=2,\n",
        "        reset_after=True,\n",
        "        recurrent_activation='sigmoid'\n",
        "    )\n",
        "),\n",
        "    Dropout(0.3),\n",
        "    BatchNormalization(),\n",
        "    Dense(GRU_UNITS, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(VOCAB_SIZE, activation='softmax')\n",
        "])\n",
        "\n",
        "# Explicitly build the model\n",
        "model.build(input_shape=(None, SEQ_LENGTH))\n",
        "\n",
        "# Compile with adjusted learning rate\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "id": "y8Ve_qTu9B4N",
        "outputId": "a706129a-0b6b-4093-c936-a51f409234ee"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │        \u001b[38;5;34m14,080\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1024\u001b[0m)      │     \u001b[38;5;34m2,365,440\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1024\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1024\u001b[0m)      │         \u001b[38;5;34m4,096\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │     \u001b[38;5;34m4,724,736\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │         \u001b[38;5;34m4,096\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m524,800\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m)             │        \u001b[38;5;34m28,215\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">14,080</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,365,440</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,724,736</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">524,800</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">28,215</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,665,463\u001b[0m (29.24 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,665,463</span> (29.24 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,661,367\u001b[0m (29.23 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,661,367</span> (29.23 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m4,096\u001b[0m (16.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> (16.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the Model"
      ],
      "metadata": {
        "id": "PbCwF_ci9IZl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Callbacks\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6),\n",
        "    ModelCheckpoint(\n",
        "        filepath='/content/drive/My Drive/ResearchStory/models/best_gru_model.h5',\n",
        "        monitor='val_loss',\n",
        "        save_best_only=True,\n",
        "        verbose=1\n",
        "    )\n",
        "]\n",
        "\n",
        "# Split data\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y_categorical, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Train\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    batch_size=128,\n",
        "    epochs=100,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5byPjLke9JHF",
        "outputId": "d0abf3b1-5caf-4327-de63-85b854a44328"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - accuracy: 0.2310 - loss: 3.0347\n",
            "Epoch 1: val_loss improved from inf to 2.61163, saving model to /content/drive/My Drive/ResearchStory/models/best_gru_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 249ms/step - accuracy: 0.2311 - loss: 3.0340 - val_accuracy: 0.3074 - val_loss: 2.6116 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - accuracy: 0.3002 - loss: 2.4300\n",
            "Epoch 2: val_loss improved from 2.61163 to 2.22253, saving model to /content/drive/My Drive/ResearchStory/models/best_gru_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 243ms/step - accuracy: 0.3002 - loss: 2.4299 - val_accuracy: 0.3513 - val_loss: 2.2225 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - accuracy: 0.3400 - loss: 2.2563\n",
            "Epoch 3: val_loss improved from 2.22253 to 2.14488, saving model to /content/drive/My Drive/ResearchStory/models/best_gru_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 244ms/step - accuracy: 0.3400 - loss: 2.2563 - val_accuracy: 0.3767 - val_loss: 2.1449 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - accuracy: 0.3626 - loss: 2.1635\n",
            "Epoch 4: val_loss improved from 2.14488 to 2.09809, saving model to /content/drive/My Drive/ResearchStory/models/best_gru_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 243ms/step - accuracy: 0.3626 - loss: 2.1635 - val_accuracy: 0.3807 - val_loss: 2.0981 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - accuracy: 0.3735 - loss: 2.1040\n",
            "Epoch 5: val_loss improved from 2.09809 to 2.06120, saving model to /content/drive/My Drive/ResearchStory/models/best_gru_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 244ms/step - accuracy: 0.3735 - loss: 2.1040 - val_accuracy: 0.3950 - val_loss: 2.0612 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - accuracy: 0.3831 - loss: 2.0550\n",
            "Epoch 6: val_loss did not improve from 2.06120\n",
            "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 239ms/step - accuracy: 0.3831 - loss: 2.0551 - val_accuracy: 0.3807 - val_loss: 2.1302 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - accuracy: 0.3911 - loss: 2.0501\n",
            "Epoch 7: val_loss did not improve from 2.06120\n",
            "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 239ms/step - accuracy: 0.3911 - loss: 2.0502 - val_accuracy: 0.3906 - val_loss: 2.0613 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - accuracy: 0.3944 - loss: 2.0098\n",
            "Epoch 8: val_loss improved from 2.06120 to 2.04190, saving model to /content/drive/My Drive/ResearchStory/models/best_gru_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 243ms/step - accuracy: 0.3944 - loss: 2.0099 - val_accuracy: 0.4016 - val_loss: 2.0419 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - accuracy: 0.4055 - loss: 1.9604\n",
            "Epoch 9: val_loss improved from 2.04190 to 2.00696, saving model to /content/drive/My Drive/ResearchStory/models/best_gru_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 244ms/step - accuracy: 0.4055 - loss: 1.9604 - val_accuracy: 0.4089 - val_loss: 2.0070 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - accuracy: 0.4215 - loss: 1.9008\n",
            "Epoch 10: val_loss improved from 2.00696 to 2.00284, saving model to /content/drive/My Drive/ResearchStory/models/best_gru_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 243ms/step - accuracy: 0.4215 - loss: 1.9008 - val_accuracy: 0.4083 - val_loss: 2.0028 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - accuracy: 0.4384 - loss: 1.8368\n",
            "Epoch 11: val_loss improved from 2.00284 to 1.98794, saving model to /content/drive/My Drive/ResearchStory/models/best_gru_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 243ms/step - accuracy: 0.4384 - loss: 1.8369 - val_accuracy: 0.4168 - val_loss: 1.9879 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - accuracy: 0.4414 - loss: 1.8129\n",
            "Epoch 12: val_loss improved from 1.98794 to 1.97892, saving model to /content/drive/My Drive/ResearchStory/models/best_gru_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 245ms/step - accuracy: 0.4414 - loss: 1.8130 - val_accuracy: 0.4188 - val_loss: 1.9789 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - accuracy: 0.4563 - loss: 1.7500\n",
            "Epoch 13: val_loss did not improve from 1.97892\n",
            "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 239ms/step - accuracy: 0.4563 - loss: 1.7501 - val_accuracy: 0.4201 - val_loss: 1.9791 - learning_rate: 0.0010\n",
            "Epoch 14/100\n",
            "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - accuracy: 0.4756 - loss: 1.6949\n",
            "Epoch 14: val_loss did not improve from 1.97892\n",
            "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 240ms/step - accuracy: 0.4756 - loss: 1.6950 - val_accuracy: 0.4144 - val_loss: 1.9857 - learning_rate: 0.0010\n",
            "Epoch 15/100\n",
            "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - accuracy: 0.4798 - loss: 1.6596\n",
            "Epoch 15: val_loss did not improve from 1.97892\n",
            "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 239ms/step - accuracy: 0.4798 - loss: 1.6597 - val_accuracy: 0.4200 - val_loss: 2.0018 - learning_rate: 0.0010\n",
            "Epoch 16/100\n",
            "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - accuracy: 0.4966 - loss: 1.6089\n",
            "Epoch 16: val_loss did not improve from 1.97892\n",
            "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 239ms/step - accuracy: 0.4966 - loss: 1.6090 - val_accuracy: 0.4190 - val_loss: 2.0134 - learning_rate: 0.0010\n",
            "Epoch 17/100\n",
            "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - accuracy: 0.5106 - loss: 1.5592\n",
            "Epoch 17: val_loss did not improve from 1.97892\n",
            "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 238ms/step - accuracy: 0.5106 - loss: 1.5594 - val_accuracy: 0.4172 - val_loss: 2.0104 - learning_rate: 0.0010\n",
            "Epoch 18/100\n",
            "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - accuracy: 0.5335 - loss: 1.4690\n",
            "Epoch 18: val_loss did not improve from 1.97892\n",
            "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 238ms/step - accuracy: 0.5335 - loss: 1.4689 - val_accuracy: 0.4263 - val_loss: 2.0302 - learning_rate: 5.0000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - accuracy: 0.5731 - loss: 1.3387\n",
            "Epoch 19: val_loss did not improve from 1.97892\n",
            "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 240ms/step - accuracy: 0.5731 - loss: 1.3387 - val_accuracy: 0.4246 - val_loss: 2.0605 - learning_rate: 5.0000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - accuracy: 0.5921 - loss: 1.2689\n",
            "Epoch 20: val_loss did not improve from 1.97892\n",
            "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 240ms/step - accuracy: 0.5920 - loss: 1.2690 - val_accuracy: 0.4219 - val_loss: 2.1095 - learning_rate: 5.0000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - accuracy: 0.6113 - loss: 1.2052\n",
            "Epoch 21: val_loss did not improve from 1.97892\n",
            "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 239ms/step - accuracy: 0.6113 - loss: 1.2053 - val_accuracy: 0.4180 - val_loss: 2.1312 - learning_rate: 5.0000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - accuracy: 0.6229 - loss: 1.1592\n",
            "Epoch 22: val_loss did not improve from 1.97892\n",
            "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 240ms/step - accuracy: 0.6229 - loss: 1.1593 - val_accuracy: 0.4175 - val_loss: 2.1624 - learning_rate: 5.0000e-04\n"
          ]
        }
      ]
    }
  ]
}