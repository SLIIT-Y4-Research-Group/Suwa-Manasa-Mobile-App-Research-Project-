{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SLIIT-Y4-Research-Group/Suwa-Manasa-Mobile-App-Research-Project-/blob/Kavindi/GRU_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tuning GRU Model for Katha Mithura"
      ],
      "metadata": {
        "id": "TOuj43Taybtl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup Google Colab & Mount Drive"
      ],
      "metadata": {
        "id": "jkNIVGOPyxt9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mount Google Drive"
      ],
      "metadata": {
        "id": "RrJ8btSLy6Qv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSZyX9ZiyLjH",
        "outputId": "6097c460-208d-4143-efa7-6e828744e053"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Navigate to dataset folder"
      ],
      "metadata": {
        "id": "5GA4uM2by-LN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "dataset_path = \"/content/drive/My Drive/ResearchStory/dataset2\"\n",
        "os.listdir(dataset_path)"
      ],
      "metadata": {
        "id": "-9qxOqbIzBCM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6943d1fa-e874-46a8-fbd9-010784989f11"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['හා හාමිගේ කතාව.txt',\n",
              " 'අම්මා.txt',\n",
              " 'ගමරාළ පිට්ටු උයපු හැටි.txt',\n",
              " 'වලිගෙ තමයි ලෙඩේ.txt',\n",
              " 'රයිගමයයි ගම්පලයයි.txt',\n",
              " 'සිල් ගත්ත පූසා.txt',\n",
              " 'රාජා හෝ, මා හෝ, ගංගා හෝ.txt',\n",
              " 'හීනැටි හාලෙ බත් කෑ ගමරාල – 2.txt',\n",
              " 'ගමරාල හීනැටි හාලෙ බත් කෑ හැටි.txt',\n",
              " 'බත් අමු වූ හැටි.txt',\n",
              " 'නටපු නැටුමකුත් නෑ බෙරේ පලුවකුත් නෑ.txt',\n",
              " 'ගමරාලගෙ දූ පොඩිත්ත – 2.txt',\n",
              " 'ගමරාලගෙ දූ පොඩිත්ත.txt',\n",
              " 'සුළඟේ ගිය පුළුන් ගුලිය – ඉතිරිය.txt',\n",
              " 'සුළඟේ ගිය පුළුන් ගුලිය.txt',\n",
              " 'රාජකීය විකට නළු අන්දරේ.txt',\n",
              " 'මහා සෝන යක්ෂයා හෙවත් රිටිගල ජයසේන.txt',\n",
              " 'ගොවියා ස්වර්ගයට ගියේය.txt',\n",
              " 'කලාගේ කතාව.txt',\n",
              " 'කටුවල කෑම.txt',\n",
              " 'ගමරාලයි නරි නයිදෙයි.txt',\n",
              " 'රජ්ජුරුවෝ කුඩු කෑවා.txt',\n",
              " 'අන්දරේ - ශ්\\u200dරී ලංකාවේ ප්\\u200dරසිද්ධ උසාවි විහිළුකාරයා.txt',\n",
              " 'රාජකීය පොකුණේ අන්දරේ.txt',\n",
              " 'අන්දරේගේ බිරිඳ සහ රැජින.txt',\n",
              " 'අන්දරේ රජුගේ ජම්බු කෑ ආකාරය.txt',\n",
              " 'මවුන්ට් ලවීනියාව.txt',\n",
              " 'සිංහබාහු.txt',\n",
              " 'රාම සහ සීතා.txt',\n",
              " 'විහාර මහා දේවි රැජින.txt',\n",
              " 'සීගිරියේ පුරාවෘත්තය.txt',\n",
              " 'ගමරාලගේ දියණිය.txt',\n",
              " 'මහා පෘථිවිය නිර්මාණය කිරීම.txt',\n",
              " 'ඉර, හඳ සහ මහා වී.txt',\n",
              " 'සෙනසුරාගේ කතාව.txt',\n",
              " 'වීදුරු කුමරිය.txt',\n",
              " 'ගෙම්බා කුමාරයා.txt',\n",
              " 'මෙනේරි වෙළෙන්දා.txt',\n",
              " 'කැස්බෑ පරෙවියා.txt',\n",
              " 'කුමාරයා සහ කුමාරිය.txt',\n",
              " 'දෙමල් ටික්කා.txt',\n",
              " 'මාතලංගෙ ලොකු-අප්පු.txt',\n",
              " 'සුදු කැස්බෑවා.txt',\n",
              " 'කළු මැණියාගේ දියණිය.txt',\n",
              " 'රන් කෑකිරි ගෙඩිය.txt',\n",
              " 'බිහිරි මිනිස්සු හතරදෙනා.txt',\n",
              " 'කුමාරයා සහ යකා.txt',\n",
              " 'යකා සහ මිනිසා සටන් කළ ආකාරය.txt',\n",
              " 'මිනිසෙක් සහ යකාවරුන් දෙදෙනෙකු.txt',\n",
              " 'ප්\\u200dරශ්න තුන.txt',\n",
              " 'විශ්වාසවන්ත නොවන රැජින.txt',\n",
              " 'පාසලට නොගිය කුමාරයා.txt',\n",
              " 'නගුල්–මුන්නා.txt',\n",
              " 'කුලේ-බකා මල්.txt',\n",
              " 'කුරුලු-ගම අප්පු – ජෝතිෂ්කාරයා.txt',\n",
              " 'යක්ෂණියක් විසින් කුමාරයෙකු පසුපස හඹා ගිය හැටි සහ සිදු වූ දේ.txt',\n",
              " 'කතා කරන අශ්වයා.txt',\n",
              " 'දුෂ්ට රජු.txt',\n",
              " 'ගැහැනු කුකුළා.txt',\n",
              " 'බොවුල්ලා සහ හරකා.txt',\n",
              " 'පාටැති රොබින්.txt',\n",
              " 'සිංහයා සහ මීමිනි.txt',\n",
              " 'මැඩිගැටළුවේ මෝඩ කබරයා.txt',\n",
              " 'ගමරාලගේ කේක්.txt',\n",
              " 'කින්නරා සහ තිලංඟන්.txt',\n",
              " 'හිවලුන් සහ කුඹුරු කඩල.txt',\n",
              " 'හිවලුන් විසින් නඩුවක් විසඳීම.txt',\n",
              " 'සිංහයා සහ කුඹුරු කඩල.txt',\n",
              " 'වඳුරා සහ නූල්කුරු කුරුල්ලෝ.txt',\n",
              " 'හිවලුන් දෙවතාවා.txt',\n",
              " 'කඩම්බාව පුද්ගලයෙකුගේ පුත්තලමට ගමන.txt',\n",
              " 'කඩම්බාව ජනතාව තමන් ගණන් කළ ආකාරය.txt',\n",
              " 'කඩම්බාව පුද්ගලයෝ සහ සිහින.txt',\n",
              " 'හතර ටොම්-ටොම් වාදකයෝ.txt',\n",
              " 'රන් ගස.txt',\n",
              " 'හත දියණියන්.txt',\n",
              " 'මහතා ජැනෙල් සින්ඤා.txt',\n",
              " 'නිකිනි කතාව.txt',\n",
              " 'ඇට්-කන්ද ලේනි.txt',\n",
              " 'විමලි කතාව.txt',\n",
              " 'තෙල් පොතු.txt',\n",
              " 'මූස් කුමාරි කතාව.txt',\n",
              " 'සීගිරිස් සින්ඤෝ, මහතා.txt',\n",
              " 'හත් දෙනෙකුගේ හොරාන් කතාව.txt',\n",
              " 'මෝඩ කොළයෙක්.txt',\n",
              " 'ගමරාල සහ රෙදිවෙළයාගේ කතාව.txt',\n",
              " 'දෙදෙනෙක්ම කපට්ටුකාරයෝ.txt',\n",
              " 'මාර්ගෝස ගස.txt',\n",
              " 'ගමරාළගේ මෝඩ පුත්.txt',\n",
              " 'හිවලාගේ විනිශ්චය.txt',\n",
              " 'ධර්ම රක්ෂිතය වූ පූසා.txt',\n",
              " 'සර්පයා සහ චිත්තියා.txt',\n",
              " 'හිවලා සහ බ්\\u200dරාහ්මණයා.txt',\n",
              " 'පුංචි රෝලය.xtx.ini',\n",
              " 'සිංහයා සහ හිවලා.txt',\n",
              " 'හන්දියන් රාක්ෂසයා කොහොම මරා දැමූහද.txt',\n",
              " 'කෘතඥ හිවලා.txt',\n",
              " 'සංඝියා හා යකඩයා ගැන.txt',\n",
              " 'තිදෙනාගේ මංගල ඉල්ලුම්කරුවන්.txt',\n",
              " 'මැඩුම සහ වඹලා.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load & Explore Dataset"
      ],
      "metadata": {
        "id": "VrQRpQhO7T_d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import re\n",
        "\n",
        "# Load dataset (adjust based on file type)\n",
        "def load_stories_from_folder(folder_path):\n",
        "    stories = []\n",
        "    for file_name in os.listdir(folder_path):\n",
        "        if file_name.endswith('.txt'):\n",
        "            with open(os.path.join(folder_path, file_name), 'r', encoding='utf-8') as f:\n",
        "                stories.append(f.read())\n",
        "    return stories\n",
        "\n",
        "stories = load_stories_from_folder(dataset_path)\n",
        "print(f\"Total stories: {len(stories)}\")\n",
        "print(\"First story preview:\", stories[0][:500])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4GvQeaM7VYk",
        "outputId": "e43a756e-3b23-4da6-8df7-9c113ad1bce2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total stories: 99\n",
            "First story preview: ඔන්න එක කැලයක ලස්සන හාවෙක් ජිවත් වුණා. මේ හාවාට තිබුණා ලස්සන දිග රැවුලක්. දවසක් මේ හාවාට හිතුණා උගේ රැවුල කපන්න. ඉතින් හාවා බාබර් සාප්පුවට ගියා රැවුල කපාගන්න.\n",
            "\n",
            "''කරුණාකරලා මගේ මේ රැවුල කපනවද?'' හාවා බාබර් උන්නැහේට කිව්වා.\n",
            "\n",
            "බාබර් උන්නැහේත් හාවාගේ රැවුල කැපුවා.\n",
            "\n",
            "හාවා හරි සතුටින් ගෙදර ගියා. ටික වෙලාවක් යනකොට හාවාට හිතුණා ''අනේ මගේ රැවුල තිබුණන් කොච්චර හොදද'' කියලා. හාවා ආපහු බාබර් සාප්පුවට ගිහින් එයාගෙ රැවුල ඉල්ලුවා.\n",
            "\n",
            "''මම කොහොමද ඔයාගේ රැවුල දෙන්නෙ. මෙච්චර වෙලා කපපු රැවුල්, කොණ්ඩ ඔක්කොම අතුගාලා දැ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clean & Preprocess Text"
      ],
      "metadata": {
        "id": "zCB6fbjy7cPk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_sinhala_text(text):\n",
        "    # Remove non-Sinhala characters and extra whitespace\n",
        "    text = re.sub(r'[^අ-ෆ.,!?…\\s]', '', text)\n",
        "    # Normalize whitespace\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "cleaned_stories = [clean_sinhala_text(story) for story in stories]\n",
        "print(\"Cleaned sample:\", cleaned_stories[0][:300])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohTs8wGa7dBE",
        "outputId": "c8405d8d-cc2b-4cf3-9900-4e68a95233a8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned sample: ඔනන එක කලයක ලසසන හවක ජවත වණ. ම හවට තබණ ලසසන දග රවලක. දවසක ම හවට හතණ උග රවල කපනන. ඉතන හව බබර සපපවට ගය රවල කපගනන. කරණකරල මග ම රවල කපනවද? හව බබර උනනහට කවව. බබර උනනහත හවග රවල කපව. හව හර සතටන ගදර ගය. ටක වලවක යනකට හවට හතණ අන මග රවල තබණන කචචර හදද කයල. හව ආපහ බබර සපපවට ගහන එයග රවල ඉලලව. මම කහමද ඔයග රවල දනන.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build Character Vocabulary"
      ],
      "metadata": {
        "id": "OE_rfTOh7lls"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine all stories\n",
        "full_text = ' '.join(cleaned_stories)\n",
        "chars = sorted(list(set(full_text)))\n",
        "print(f\"Total unique characters: {len(chars)}\")\n",
        "\n",
        "# Create character mappings\n",
        "char_to_idx = {ch: i for i, ch in enumerate(chars)}\n",
        "idx_to_char = {i: ch for i, ch in enumerate(chars)}\n",
        "\n",
        "# Save vocabulary\n",
        "vocab_path = \"/content/drive/My Drive/ResearchStory/vocabulary/\"\n",
        "os.makedirs(vocab_path, exist_ok=True)\n",
        "\n",
        "with open(os.path.join(vocab_path, 'char_to_idx.json'), 'w', encoding='utf-8') as f:\n",
        "    json.dump(char_to_idx, f, ensure_ascii=False)\n",
        "\n",
        "with open(os.path.join(vocab_path, 'idx_to_char.json'), 'w', encoding='utf-8') as f:\n",
        "    json.dump(idx_to_char, f, ensure_ascii=False)\n",
        "\n",
        "print(\"Vocabulary saved.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjqNViIf7mck",
        "outputId": "4b41e611-7126-43f5-a2f1-5fb92e5bfe5f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total unique characters: 55\n",
            "Vocabulary saved.\n"
          ]
        }
      ]
    }
  ]
}